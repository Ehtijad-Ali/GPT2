# -*- coding: utf-8 -*-
"""Simple_ChatBot1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YU-1l6BVeqVLQ_AHhX6XFX6KEqpIi7m1
"""

import streamlit as st
import os
from transformers import AutoModelForCausalLM, AutoTokenizer
from langchain.llms import HuggingFaceHub

os.environ['HFI_TOKEN'] = sec_key

repo_id = 'openai-community/gpt2'
tokenizer = AutoTokenizer.from_pretrained(repo_id)
model = AutoModelForCausalLM.from_pretrained(repo_id)

llm = HuggingFaceHub(repo_id=repo_id)

st.title('Free GPT-2')
st.write('This is a free GPT-2 model that you can use to generate text.')

user_input = st.text_input('Enter your prompt')

if st.button('Send'):
    if user_input:
        try:
            input_ids = tokenizer(user_input, return_tensors="pt").input_ids
            output = model.generate(input_ids)
            response = tokenizer.decode(output[0], skip_special_tokens=True)
            st.write(f"Bot: {response}")
        except Exception as e:
            st.error(f"Error: {str(e)}")
    else:
        st.write('Please enter a prompt')